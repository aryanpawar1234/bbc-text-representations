{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BBC Text Representations - Sparse Methods\n",
    "\n",
    "**Roll Number:** SE22UARI195\n",
    "\n",
    "**Tasks:**\n",
    "1. One-Hot Encoding (OHE) - Top 2000 tokens\n",
    "2. Bag-of-Words (BoW) - Unigram counts\n",
    "3. N-grams - Unigrams + Bigrams\n",
    "4. TF-IDF - With manual verification\n",
    "5. Calculate health metrics for all methods\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports successful!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# Progress bar\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "print(\"‚úÖ Imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roll Number: SE22UARI195\n",
      "Cache Directory: ../cache\n",
      "Models Directory: ../models\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "ROLL = \"SE22UARI195\"\n",
    "CACHE_DIR = Path(\"../cache\")\n",
    "MODELS_DIR = Path(\"../models\")\n",
    "MODELS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Roll Number: {ROLL}\")\n",
    "print(f\"Cache Directory: {CACHE_DIR}\")\n",
    "print(f\"Models Directory: {MODELS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading preprocessed data...\n",
      "\n",
      "‚úÖ TRAIN: 1335 documents\n",
      "‚úÖ DEV: 445 documents\n",
      "‚úÖ TEST: 445 documents\n",
      "‚úÖ Vocabulary: 20,404 unique tokens\n",
      "‚úÖ Metadata loaded\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed data\n",
    "print(\"üìÇ Loading preprocessed data...\\n\")\n",
    "\n",
    "with open(CACHE_DIR / 'train_processed.pkl', 'rb') as f:\n",
    "    train_df = pickle.load(f)\n",
    "print(f\"‚úÖ TRAIN: {len(train_df)} documents\")\n",
    "\n",
    "with open(CACHE_DIR / 'dev_processed.pkl', 'rb') as f:\n",
    "    dev_df = pickle.load(f)\n",
    "print(f\"‚úÖ DEV: {len(dev_df)} documents\")\n",
    "\n",
    "with open(CACHE_DIR / 'test_processed.pkl', 'rb') as f:\n",
    "    test_df = pickle.load(f)\n",
    "print(f\"‚úÖ TEST: {len(test_df)} documents\")\n",
    "\n",
    "with open(CACHE_DIR / 'vocab_counter.pkl', 'rb') as f:\n",
    "    vocab_counter = pickle.load(f)\n",
    "print(f\"‚úÖ Vocabulary: {len(vocab_counter):,} unique tokens\")\n",
    "\n",
    "with open(CACHE_DIR / 'metadata.pkl', 'rb') as f:\n",
    "    metadata = pickle.load(f)\n",
    "print(f\"‚úÖ Metadata loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Data shapes:\n",
      "  TRAIN: 1335 documents\n",
      "  DEV: 445 documents\n",
      "  TEST: 445 documents\n"
     ]
    }
   ],
   "source": [
    "# Extract processed text for vectorization\n",
    "X_train_text = train_df['text_processed'].values\n",
    "X_dev_text = dev_df['text_processed'].values\n",
    "X_test_text = test_df['text_processed'].values\n",
    "\n",
    "y_train = train_df['label'].values\n",
    "y_dev = dev_df['label'].values\n",
    "y_test = test_df['label'].values\n",
    "\n",
    "print(\"\\nüìä Data shapes:\")\n",
    "print(f\"  TRAIN: {len(X_train_text)} documents\")\n",
    "print(f\"  DEV: {len(X_dev_text)} documents\")\n",
    "print(f\"  TEST: {len(X_test_text)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Helper Functions for Health Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Helper functions defined!\n"
     ]
    }
   ],
   "source": [
    "def calculate_health_metrics(X_matrix, vectorizer, X_test_matrix, test_tokens_list, \n",
    "                            fit_time, transform_times, method_name):\n",
    "    \"\"\"\n",
    "    Calculate comprehensive health metrics for a representation.\n",
    "    \n",
    "    Args:\n",
    "        X_matrix: Training matrix (sparse or dense)\n",
    "        vectorizer: Fitted vectorizer object\n",
    "        X_test_matrix: Test matrix\n",
    "        test_tokens_list: List of token lists for test set\n",
    "        fit_time: Time taken to fit (seconds)\n",
    "        transform_times: List of transform times per document (seconds)\n",
    "        method_name: Name of the method\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of metrics\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    # Vocabulary size\n",
    "    if hasattr(vectorizer, 'vocabulary_'):\n",
    "        metrics['V'] = len(vectorizer.vocabulary_)\n",
    "    else:\n",
    "        metrics['V'] = X_matrix.shape[1]\n",
    "    \n",
    "    # Non-zero entries\n",
    "    if sp.issparse(X_matrix):\n",
    "        metrics['nnz'] = int(X_matrix.nnz)\n",
    "    else:\n",
    "        metrics['nnz'] = int(np.count_nonzero(X_matrix))\n",
    "    \n",
    "    # Sparsity\n",
    "    total_elements = X_matrix.shape[0] * X_matrix.shape[1]\n",
    "    metrics['sparsity'] = float(1 - metrics['nnz'] / total_elements)\n",
    "    \n",
    "    # OOV rate on test set\n",
    "    if hasattr(vectorizer, 'vocabulary_'):\n",
    "        train_vocab = set(vectorizer.vocabulary_.keys())\n",
    "        total_test_tokens = 0\n",
    "        oov_tokens = 0\n",
    "        \n",
    "        for tokens in test_tokens_list:\n",
    "            total_test_tokens += len(tokens)\n",
    "            oov_tokens += sum(1 for t in tokens if t not in train_vocab)\n",
    "        \n",
    "        metrics['oov'] = float(oov_tokens / total_test_tokens) if total_test_tokens > 0 else 0.0\n",
    "    else:\n",
    "        metrics['oov'] = 0.0\n",
    "    \n",
    "    # Top-k coverage (only for TF-IDF)\n",
    "    metrics['topk_100'] = 0.0\n",
    "    metrics['topk_500'] = 0.0\n",
    "    \n",
    "    # Timing\n",
    "    metrics['fit_s'] = float(fit_time)\n",
    "    metrics['ms_per_doc'] = float(np.mean(transform_times) * 1000)  # Convert to ms\n",
    "    \n",
    "    # Memory\n",
    "    if sp.issparse(X_matrix):\n",
    "        # Sparse matrix memory\n",
    "        mem_bytes = X_matrix.data.nbytes + X_matrix.indices.nbytes + X_matrix.indptr.nbytes\n",
    "    else:\n",
    "        # Dense matrix memory\n",
    "        mem_bytes = X_matrix.nbytes\n",
    "    \n",
    "    metrics['mem_mb'] = float(mem_bytes / (1024 * 1024))\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def print_metrics(metrics, method_name):\n",
    "    \"\"\"Pretty print metrics.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üìä {method_name} - Health Metrics\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"  Vocabulary size (V):        {metrics['V']:>10,}\")\n",
    "    print(f\"  Non-zero entries (nnz):     {metrics['nnz']:>10,}\")\n",
    "    print(f\"  Sparsity:                   {metrics['sparsity']:>10.4f}\")\n",
    "    print(f\"  OOV rate (TEST):            {metrics['oov']:>10.4f}\")\n",
    "    if metrics['topk_100'] > 0:\n",
    "        print(f\"  Top-100 coverage:           {metrics['topk_100']:>10.4f}\")\n",
    "        print(f\"  Top-500 coverage:           {metrics['topk_500']:>10.4f}\")\n",
    "    print(f\"  Fit time (s):               {metrics['fit_s']:>10.3f}\")\n",
    "    print(f\"  Transform time (ms/doc):    {metrics['ms_per_doc']:>10.3f}\")\n",
    "    print(f\"  Memory (MB):                {metrics['mem_mb']:>10.2f}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "print(\"‚úÖ Helper functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. One-Hot Encoding (OHE)\n",
    "\n",
    "Top 2000 tokens by frequency in TRAIN, binary 0/1 per document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Building One-Hot Encoding (OHE)...\n",
      "\n",
      "Selected top 2000 tokens\n",
      "\n",
      "Top 20 tokens: ['said', 'year', 'mr', 'would', 'also', 'people', 'new', 'one', 'time', 'could', 'game', 'last', 'two', 'first', 'world', 'say', 'film', 'company', 'firm', 'make']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîß Building One-Hot Encoding (OHE)...\\n\")\n",
    "\n",
    "# Get top 2000 tokens from vocab_counter\n",
    "top_2000_tokens = [token for token, count in vocab_counter.most_common(2000)]\n",
    "\n",
    "print(f\"Selected top 2000 tokens\")\n",
    "print(f\"\\nTop 20 tokens: {top_2000_tokens[:20]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OHE fitted on TRAIN in 0.224s\n",
      "   Shape: (1335, 2000)\n"
     ]
    }
   ],
   "source": [
    "# Create vectorizer with fixed vocabulary\n",
    "ohe_vectorizer = CountVectorizer(\n",
    "    vocabulary=top_2000_tokens,\n",
    "    binary=True,  # Binary encoding (0/1)\n",
    "    lowercase=False,  # Already preprocessed\n",
    "    token_pattern=r'(?u)\\b\\w+\\b'\n",
    ")\n",
    "\n",
    "# Fit and transform TRAIN\n",
    "start_time = time.time()\n",
    "X_train_ohe = ohe_vectorizer.fit_transform(X_train_text)\n",
    "fit_time_ohe = time.time() - start_time\n",
    "\n",
    "print(f\"‚úÖ OHE fitted on TRAIN in {fit_time_ohe:.3f}s\")\n",
    "print(f\"   Shape: {X_train_ohe.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OHE transformed DEV in 0.058s\n",
      "‚úÖ OHE transformed TEST in 0.053s\n"
     ]
    }
   ],
   "source": [
    "# Transform DEV and TEST\n",
    "transform_times_ohe = []\n",
    "\n",
    "# DEV\n",
    "start = time.time()\n",
    "X_dev_ohe = ohe_vectorizer.transform(X_dev_text)\n",
    "dev_time = time.time() - start\n",
    "transform_times_ohe.append(dev_time / len(X_dev_text))\n",
    "\n",
    "# TEST\n",
    "start = time.time()\n",
    "X_test_ohe = ohe_vectorizer.transform(X_test_text)\n",
    "test_time = time.time() - start\n",
    "transform_times_ohe.append(test_time / len(X_test_text))\n",
    "\n",
    "print(f\"‚úÖ OHE transformed DEV in {dev_time:.3f}s\")\n",
    "print(f\"‚úÖ OHE transformed TEST in {test_time:.3f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìä One-Hot Encoding (OHE) - Health Metrics\n",
      "============================================================\n",
      "  Vocabulary size (V):             2,000\n",
      "  Non-zero entries (nnz):        134,064\n",
      "  Sparsity:                       0.9498\n",
      "  OOV rate (TEST):                0.2863\n",
      "  Fit time (s):                    0.224\n",
      "  Transform time (ms/doc):         0.124\n",
      "  Memory (MB):                      1.54\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Calculate health metrics\n",
    "ohe_metrics = calculate_health_metrics(\n",
    "    X_train_ohe, ohe_vectorizer, X_test_ohe, test_df['tokens'].tolist(),\n",
    "    fit_time_ohe, transform_times_ohe, \"OHE\"\n",
    ")\n",
    "\n",
    "print_metrics(ohe_metrics, \"One-Hot Encoding (OHE)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ OHE artifacts saved!\n"
     ]
    }
   ],
   "source": [
    "# Save OHE artifacts\n",
    "with open(MODELS_DIR / 'ohe_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(ohe_vectorizer, f)\n",
    "\n",
    "sp.save_npz(MODELS_DIR / 'X_train_ohe.npz', X_train_ohe)\n",
    "sp.save_npz(MODELS_DIR / 'X_dev_ohe.npz', X_dev_ohe)\n",
    "sp.save_npz(MODELS_DIR / 'X_test_ohe.npz', X_test_ohe)\n",
    "\n",
    "print(\"\\nüíæ OHE artifacts saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bag-of-Words (BoW)\n",
    "\n",
    "Unigram counts with min_df >= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Building Bag-of-Words (BoW)...\n",
      "\n",
      "‚úÖ BoW fitted on TRAIN in 0.221s\n",
      "   Shape: (1335, 11515)\n",
      "   Vocabulary size: 11,515\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîß Building Bag-of-Words (BoW)...\\n\")\n",
    "\n",
    "# Create BoW vectorizer\n",
    "bow_vectorizer = CountVectorizer(\n",
    "    min_df=2,  # Minimum document frequency\n",
    "    lowercase=False,  # Already preprocessed\n",
    "    token_pattern=r'(?u)\\b\\w+\\b'\n",
    ")\n",
    "\n",
    "# Fit and transform TRAIN\n",
    "start_time = time.time()\n",
    "X_train_bow = bow_vectorizer.fit_transform(X_train_text)\n",
    "fit_time_bow = time.time() - start_time\n",
    "\n",
    "print(f\"‚úÖ BoW fitted on TRAIN in {fit_time_bow:.3f}s\")\n",
    "print(f\"   Shape: {X_train_bow.shape}\")\n",
    "print(f\"   Vocabulary size: {len(bow_vectorizer.vocabulary_):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ BoW transformed DEV in 0.069s\n",
      "‚úÖ BoW transformed TEST in 0.085s\n"
     ]
    }
   ],
   "source": [
    "# Transform DEV and TEST\n",
    "transform_times_bow = []\n",
    "\n",
    "# DEV\n",
    "start = time.time()\n",
    "X_dev_bow = bow_vectorizer.transform(X_dev_text)\n",
    "dev_time = time.time() - start\n",
    "transform_times_bow.append(dev_time / len(X_dev_text))\n",
    "\n",
    "# TEST\n",
    "start = time.time()\n",
    "X_test_bow = bow_vectorizer.transform(X_test_text)\n",
    "test_time = time.time() - start\n",
    "transform_times_bow.append(test_time / len(X_test_text))\n",
    "\n",
    "print(f\"‚úÖ BoW transformed DEV in {dev_time:.3f}s\")\n",
    "print(f\"‚úÖ BoW transformed TEST in {test_time:.3f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìä Bag-of-Words (BoW) - Health Metrics\n",
      "============================================================\n",
      "  Vocabulary size (V):            11,515\n",
      "  Non-zero entries (nnz):        186,739\n",
      "  Sparsity:                       0.9879\n",
      "  OOV rate (TEST):                0.0706\n",
      "  Fit time (s):                    0.221\n",
      "  Transform time (ms/doc):         0.173\n",
      "  Memory (MB):                      2.14\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Calculate health metrics\n",
    "bow_metrics = calculate_health_metrics(\n",
    "    X_train_bow, bow_vectorizer, X_test_bow, test_df['tokens'].tolist(),\n",
    "    fit_time_bow, transform_times_bow, \"BoW\"\n",
    ")\n",
    "\n",
    "print_metrics(bow_metrics, \"Bag-of-Words (BoW)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ BoW artifacts saved!\n"
     ]
    }
   ],
   "source": [
    "# Save BoW artifacts\n",
    "with open(MODELS_DIR / 'bow_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(bow_vectorizer, f)\n",
    "\n",
    "sp.save_npz(MODELS_DIR / 'X_train_bow.npz', X_train_bow)\n",
    "sp.save_npz(MODELS_DIR / 'X_dev_bow.npz', X_dev_bow)\n",
    "sp.save_npz(MODELS_DIR / 'X_test_bow.npz', X_test_bow)\n",
    "\n",
    "print(\"\\nüíæ BoW artifacts saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. N-grams (Unigrams + Bigrams)\n",
    "\n",
    "Unigrams + bigrams with min_df >= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Building N-grams (1,2)...\n",
      "\n",
      "‚úÖ N-gram fitted on TRAIN in 0.724s\n",
      "   Shape: (1335, 18625)\n",
      "   Vocabulary size: 18,625\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîß Building N-grams (1,2)...\\n\")\n",
    "\n",
    "# Create N-gram vectorizer\n",
    "ngram_vectorizer = CountVectorizer(\n",
    "    ngram_range=(1, 2),  # Unigrams + bigrams\n",
    "    min_df=3,  # Minimum document frequency\n",
    "    lowercase=False,  # Already preprocessed\n",
    "    token_pattern=r'(?u)\\b\\w+\\b'\n",
    ")\n",
    "\n",
    "# Fit and transform TRAIN\n",
    "start_time = time.time()\n",
    "X_train_ngram = ngram_vectorizer.fit_transform(X_train_text)\n",
    "fit_time_ngram = time.time() - start_time\n",
    "\n",
    "print(f\"‚úÖ N-gram fitted on TRAIN in {fit_time_ngram:.3f}s\")\n",
    "print(f\"   Shape: {X_train_ngram.shape}\")\n",
    "print(f\"   Vocabulary size: {len(ngram_vectorizer.vocabulary_):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Vocabulary breakdown:\n",
      "   Unigrams: 8,508 (45.7%)\n",
      "   Bigrams:  10,117 (54.3%)\n",
      "\n",
      "   Example bigrams: ['worldcom bos', 'former worldcom', 'bos bernie', 'bernie ebbers', 'accused overseeing', 'overseeing 11bn', 'made comment', 'defence lawyer', 'mr ebbers', 'phone company']\n"
     ]
    }
   ],
   "source": [
    "# Check unigram vs bigram distribution\n",
    "vocab = ngram_vectorizer.vocabulary_\n",
    "unigrams = sum(1 for term in vocab.keys() if ' ' not in term)\n",
    "bigrams = sum(1 for term in vocab.keys() if ' ' in term)\n",
    "\n",
    "print(f\"\\nüìä Vocabulary breakdown:\")\n",
    "print(f\"   Unigrams: {unigrams:,} ({unigrams/len(vocab)*100:.1f}%)\")\n",
    "print(f\"   Bigrams:  {bigrams:,} ({bigrams/len(vocab)*100:.1f}%)\")\n",
    "\n",
    "# Show some example bigrams\n",
    "bigram_list = [term for term in vocab.keys() if ' ' in term]\n",
    "print(f\"\\n   Example bigrams: {bigram_list[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ N-gram transformed DEV in 0.178s\n",
      "‚úÖ N-gram transformed TEST in 0.155s\n"
     ]
    }
   ],
   "source": [
    "# Transform DEV and TEST\n",
    "transform_times_ngram = []\n",
    "\n",
    "# DEV\n",
    "start = time.time()\n",
    "X_dev_ngram = ngram_vectorizer.transform(X_dev_text)\n",
    "dev_time = time.time() - start\n",
    "transform_times_ngram.append(dev_time / len(X_dev_text))\n",
    "\n",
    "# TEST\n",
    "start = time.time()\n",
    "X_test_ngram = ngram_vectorizer.transform(X_test_text)\n",
    "test_time = time.time() - start\n",
    "transform_times_ngram.append(test_time / len(X_test_text))\n",
    "\n",
    "print(f\"\\n‚úÖ N-gram transformed DEV in {dev_time:.3f}s\")\n",
    "print(f\"‚úÖ N-gram transformed TEST in {test_time:.3f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìä N-grams (1,2) - Health Metrics\n",
      "============================================================\n",
      "  Vocabulary size (V):            18,625\n",
      "  Non-zero entries (nnz):        230,909\n",
      "  Sparsity:                       0.9907\n",
      "  OOV rate (TEST):                0.0935\n",
      "  Fit time (s):                    0.724\n",
      "  Transform time (ms/doc):         0.374\n",
      "  Memory (MB):                      2.65\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Calculate health metrics\n",
    "ngram_metrics = calculate_health_metrics(\n",
    "    X_train_ngram, ngram_vectorizer, X_test_ngram, test_df['tokens'].tolist(),\n",
    "    fit_time_ngram, transform_times_ngram, \"N-gram\"\n",
    ")\n",
    "\n",
    "print_metrics(ngram_metrics, \"N-grams (1,2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ N-gram artifacts saved!\n"
     ]
    }
   ],
   "source": [
    "# Save N-gram artifacts\n",
    "with open(MODELS_DIR / 'ngram_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(ngram_vectorizer, f)\n",
    "\n",
    "sp.save_npz(MODELS_DIR / 'X_train_ngram.npz', X_train_ngram)\n",
    "sp.save_npz(MODELS_DIR / 'X_dev_ngram.npz', X_dev_ngram)\n",
    "sp.save_npz(MODELS_DIR / 'X_test_ngram.npz', X_test_ngram)\n",
    "\n",
    "print(\"\\nüíæ N-gram artifacts saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. TF-IDF\n",
    "\n",
    "With smoothed IDF: idf(t) = log((N + 1)/(df(t) + 1)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Building TF-IDF...\n",
      "\n",
      "‚úÖ TF-IDF fitted on TRAIN in 0.200s\n",
      "   Shape: (1335, 11515)\n",
      "   Vocabulary size: 11,515\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîß Building TF-IDF...\\n\")\n",
    "\n",
    "# Create TF-IDF vectorizer with sklearn's default smoothing\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    min_df=2,\n",
    "    lowercase=False,\n",
    "    token_pattern=r'(?u)\\b\\w+\\b',\n",
    "    smooth_idf=True,  # Use smoothed IDF\n",
    "    sublinear_tf=False  # Use raw term frequency\n",
    ")\n",
    "\n",
    "# Fit and transform TRAIN\n",
    "start_time = time.time()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_text)\n",
    "fit_time_tfidf = time.time() - start_time\n",
    "\n",
    "print(f\"‚úÖ TF-IDF fitted on TRAIN in {fit_time_tfidf:.3f}s\")\n",
    "print(f\"   Shape: {X_train_tfidf.shape}\")\n",
    "print(f\"   Vocabulary size: {len(tfidf_vectorizer.vocabulary_):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ TF-IDF transformed DEV in 0.064s\n",
      "‚úÖ TF-IDF transformed TEST in 0.061s\n"
     ]
    }
   ],
   "source": [
    "# Transform DEV and TEST\n",
    "transform_times_tfidf = []\n",
    "\n",
    "# DEV\n",
    "start = time.time()\n",
    "X_dev_tfidf = tfidf_vectorizer.transform(X_dev_text)\n",
    "dev_time = time.time() - start\n",
    "transform_times_tfidf.append(dev_time / len(X_dev_text))\n",
    "\n",
    "# TEST\n",
    "start = time.time()\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test_text)\n",
    "test_time = time.time() - start\n",
    "transform_times_tfidf.append(test_time / len(X_test_text))\n",
    "\n",
    "print(f\"‚úÖ TF-IDF transformed DEV in {dev_time:.3f}s\")\n",
    "print(f\"‚úÖ TF-IDF transformed TEST in {test_time:.3f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual TF-IDF Verification\n",
    "\n",
    "Verify sklearn's TF-IDF matches manual calculation (within 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Manual TF-IDF Verification...\n",
      "\n",
      "Documents for verification:\n",
      "  Doc 0: worldcom bos left book alone former worldcom bos bernie ebbers accused overseein...\n",
      "  Doc 1: yeading face newcastle fa cup premiership side newcastle united face trip ryman ...\n",
      "  Doc 2: ocean twelve raid box office ocean twelve crime caper sequel starring george clo...\n",
      "\n",
      "\n",
      "Tokenized docs:\n",
      "  Doc 0: ['worldcom', 'bos', 'left', 'book', 'alone', 'former', 'worldcom', 'bos', 'bernie', 'ebbers']... (187 tokens)\n",
      "  Doc 1: ['yeading', 'face', 'newcastle', 'fa', 'cup', 'premiership', 'side', 'newcastle', 'united', 'face']... (239 tokens)\n",
      "  Doc 2: ['ocean', 'twelve', 'raid', 'box', 'office', 'ocean', 'twelve', 'crime', 'caper', 'sequel']... (176 tokens)\n",
      "\n",
      "Vocabulary size: 411\n",
      "\n",
      "TF matrix shape: (3, 411)\n",
      "\n",
      "Sample IDF values (first 5 terms):\n",
      "  loss           : df=1, idf=1.693147\n",
      "  know           : df=1, idf=1.693147\n",
      "  admitted       : df=1, idf=1.693147\n",
      "  alone          : df=1, idf=1.693147\n",
      "  11bn           : df=1, idf=1.693147\n",
      "\n",
      "Manual TF-IDF matrix shape: (3, 411)\n",
      "\n",
      "üìä Verification Results:\n",
      "  Max difference: 3.33e-16\n",
      "  ‚úÖ Match: Manual and sklearn TF-IDF agree within tolerance!\n",
      "\n",
      "  Sample TF-IDF values (Doc 0, first 5 non-zero terms):\n",
      "    Term            Manual       Sklearn      Diff        \n",
      "    --------------------------------------------------\n",
      "    loss            0.043749     0.043749     2.78e-17    \n",
      "    know            0.043749     0.043749     2.78e-17    \n",
      "    admitted        0.087498     0.087498     5.55e-17    \n",
      "    alone           0.043749     0.043749     2.78e-17    \n",
      "    11bn            0.043749     0.043749     2.78e-17    \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîç Manual TF-IDF Verification...\\n\")\n",
    "\n",
    "# Take first 3 documents as tiny example\n",
    "tiny_docs = X_train_text[:3]\n",
    "print(\"Documents for verification:\")\n",
    "for i, doc in enumerate(tiny_docs):\n",
    "    print(f\"  Doc {i}: {doc[:80]}...\")\n",
    "\n",
    "# Fit sklearn TF-IDF on tiny corpus\n",
    "tiny_vectorizer = TfidfVectorizer(\n",
    "    lowercase=False,\n",
    "    token_pattern=r'(?u)\\b\\w+\\b',\n",
    "    smooth_idf=True\n",
    ")\n",
    "X_tiny_sklearn = tiny_vectorizer.fit_transform(tiny_docs).toarray()\n",
    "\n",
    "# Manual calculation\n",
    "from collections import Counter\n",
    "\n",
    "# Tokenize documents\n",
    "tiny_tokens = [doc.split() for doc in tiny_docs]\n",
    "print(f\"\\n\\nTokenized docs:\")\n",
    "for i, tokens in enumerate(tiny_tokens):\n",
    "    print(f\"  Doc {i}: {tokens[:10]}... ({len(tokens)} tokens)\")\n",
    "\n",
    "# Build vocabulary\n",
    "vocab = {}\n",
    "idx = 0\n",
    "for tokens in tiny_tokens:\n",
    "    for token in set(tokens):\n",
    "        if token not in vocab:\n",
    "            vocab[token] = idx\n",
    "            idx += 1\n",
    "\n",
    "print(f\"\\nVocabulary size: {len(vocab)}\")\n",
    "\n",
    "# Calculate TF (term frequency)\n",
    "N = len(tiny_docs)\n",
    "V = len(vocab)\n",
    "\n",
    "# Initialize TF matrix\n",
    "tf_matrix = np.zeros((N, V))\n",
    "for doc_idx, tokens in enumerate(tiny_tokens):\n",
    "    token_counts = Counter(tokens)\n",
    "    for token, count in token_counts.items():\n",
    "        if token in vocab:\n",
    "            tf_matrix[doc_idx, vocab[token]] = count\n",
    "\n",
    "print(f\"\\nTF matrix shape: {tf_matrix.shape}\")\n",
    "\n",
    "# Calculate DF (document frequency)\n",
    "df = np.zeros(V)\n",
    "for doc_idx, tokens in enumerate(tiny_tokens):\n",
    "    for token in set(tokens):\n",
    "        if token in vocab:\n",
    "            df[vocab[token]] += 1\n",
    "\n",
    "# Calculate IDF with smoothing: log((N+1)/(df+1)) + 1\n",
    "idf = np.log((N + 1) / (df + 1)) + 1\n",
    "\n",
    "print(f\"\\nSample IDF values (first 5 terms):\")\n",
    "vocab_list = list(vocab.keys())[:5]\n",
    "for term in vocab_list:\n",
    "    term_idx = vocab[term]\n",
    "    print(f\"  {term:15s}: df={df[term_idx]:.0f}, idf={idf[term_idx]:.6f}\")\n",
    "\n",
    "# Calculate TF-IDF\n",
    "tfidf_manual = tf_matrix * idf\n",
    "\n",
    "# Normalize rows to unit length (L2 normalization)\n",
    "row_norms = np.sqrt(np.sum(tfidf_manual**2, axis=1, keepdims=True))\n",
    "row_norms[row_norms == 0] = 1  # Avoid division by zero\n",
    "tfidf_manual = tfidf_manual / row_norms\n",
    "\n",
    "print(f\"\\nManual TF-IDF matrix shape: {tfidf_manual.shape}\")\n",
    "\n",
    "# Compare with sklearn (reorder columns to match)\n",
    "sklearn_vocab_inv = {idx: term for term, idx in tiny_vectorizer.vocabulary_.items()}\n",
    "manual_to_sklearn = [tiny_vectorizer.vocabulary_[term] for term in vocab.keys() if term in tiny_vectorizer.vocabulary_]\n",
    "\n",
    "# Get matching subset\n",
    "X_tiny_sklearn_reordered = X_tiny_sklearn[:, manual_to_sklearn]\n",
    "tfidf_manual_subset = tfidf_manual[:, :len(manual_to_sklearn)]\n",
    "\n",
    "# Calculate difference\n",
    "diff = np.abs(X_tiny_sklearn_reordered - tfidf_manual_subset)\n",
    "max_diff = np.max(diff)\n",
    "\n",
    "print(f\"\\nüìä Verification Results:\")\n",
    "print(f\"  Max difference: {max_diff:.2e}\")\n",
    "if max_diff < 1e-6:\n",
    "    print(f\"  ‚úÖ Match: Manual and sklearn TF-IDF agree within tolerance!\")\n",
    "else:\n",
    "    print(f\"  ‚ùå Mismatch: Difference exceeds tolerance\")\n",
    "\n",
    "# Show a sample comparison\n",
    "print(f\"\\n  Sample TF-IDF values (Doc 0, first 5 non-zero terms):\")\n",
    "print(f\"    {'Term':<15s} {'Manual':<12s} {'Sklearn':<12s} {'Diff':<12s}\")\n",
    "print(f\"    {'-'*50}\")\n",
    "    \n",
    "sample_indices = np.where(tfidf_manual_subset[0] > 0)[0][:5]\n",
    "for idx in sample_indices:\n",
    "    term = list(vocab.keys())[idx]\n",
    "    manual_val = tfidf_manual_subset[0, idx]\n",
    "    sklearn_val = X_tiny_sklearn_reordered[0, idx]\n",
    "    diff_val = abs(manual_val - sklearn_val)\n",
    "    print(f\"    {term:<15s} {manual_val:<12.6f} {sklearn_val:<12.6f} {diff_val:<12.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Calculating top-k coverage...\n",
      "\n",
      "Top-100 coverage: 0.1195 (11.95%)\n",
      "Top-500 coverage: 0.3344 (33.44%)\n",
      "\n",
      "üîù Top-10 most important terms (by avg TF-IDF):\n",
      "   1. said            : 0.040767\n",
      "   2. mr              : 0.028011\n",
      "   3. year            : 0.023712\n",
      "   4. would           : 0.019603\n",
      "   5. game            : 0.018427\n",
      "   6. film            : 0.018066\n",
      "   7. people          : 0.017062\n",
      "   8. new             : 0.016816\n",
      "   9. also            : 0.016027\n",
      "  10. one             : 0.015069\n"
     ]
    }
   ],
   "source": [
    "# Calculate top-k coverage\n",
    "print(\"\\nüìä Calculating top-k coverage...\\n\")\n",
    "\n",
    "# Get average TF-IDF per term across all documents\n",
    "term_importance = np.array(X_train_tfidf.mean(axis=0)).flatten()\n",
    "\n",
    "# Get indices of top-k terms\n",
    "top_k_indices = {}\n",
    "top_k_indices[100] = np.argsort(term_importance)[-100:]\n",
    "top_k_indices[500] = np.argsort(term_importance)[-500:]\n",
    "\n",
    "# Calculate coverage: sum of TF-IDF mass for top-k terms / total mass\n",
    "total_mass = X_train_tfidf.sum()\n",
    "\n",
    "topk_100_mass = X_train_tfidf[:, top_k_indices[100]].sum()\n",
    "topk_500_mass = X_train_tfidf[:, top_k_indices[500]].sum()\n",
    "\n",
    "topk_100_coverage = float(topk_100_mass / total_mass)\n",
    "topk_500_coverage = float(topk_500_mass / total_mass)\n",
    "\n",
    "print(f\"Top-100 coverage: {topk_100_coverage:.4f} ({topk_100_coverage*100:.2f}%)\")\n",
    "print(f\"Top-500 coverage: {topk_500_coverage:.4f} ({topk_500_coverage*100:.2f}%)\")\n",
    "\n",
    "# Show top-10 terms\n",
    "vocab_list = list(tfidf_vectorizer.vocabulary_.keys())\n",
    "vocab_indices = list(tfidf_vectorizer.vocabulary_.values())\n",
    "idx_to_term = {idx: term for term, idx in tfidf_vectorizer.vocabulary_.items()}\n",
    "\n",
    "top_10_indices = np.argsort(term_importance)[-10:][::-1]\n",
    "print(f\"\\nüîù Top-10 most important terms (by avg TF-IDF):\")\n",
    "for rank, idx in enumerate(top_10_indices, 1):\n",
    "    term = idx_to_term[idx]\n",
    "    importance = term_importance[idx]\n",
    "    print(f\"  {rank:2d}. {term:15s} : {importance:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìä TF-IDF - Health Metrics\n",
      "============================================================\n",
      "  Vocabulary size (V):            11,515\n",
      "  Non-zero entries (nnz):        186,739\n",
      "  Sparsity:                       0.9879\n",
      "  OOV rate (TEST):                0.0706\n",
      "  Top-100 coverage:               0.1195\n",
      "  Top-500 coverage:               0.3344\n",
      "  Fit time (s):                    0.200\n",
      "  Transform time (ms/doc):         0.141\n",
      "  Memory (MB):                      2.14\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Calculate health metrics with top-k coverage\n",
    "tfidf_metrics = calculate_health_metrics(\n",
    "    X_train_tfidf, tfidf_vectorizer, X_test_tfidf, test_df['tokens'].tolist(),\n",
    "    fit_time_tfidf, transform_times_tfidf, \"TF-IDF\"\n",
    ")\n",
    "\n",
    "# Add top-k coverage\n",
    "tfidf_metrics['topk_100'] = topk_100_coverage\n",
    "tfidf_metrics['topk_500'] = topk_500_coverage\n",
    "\n",
    "print_metrics(tfidf_metrics, \"TF-IDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ TF-IDF artifacts saved!\n"
     ]
    }
   ],
   "source": [
    "# Save TF-IDF artifacts\n",
    "with open(MODELS_DIR / 'tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf_vectorizer, f)\n",
    "\n",
    "sp.save_npz(MODELS_DIR / 'X_train_tfidf.npz', X_train_tfidf)\n",
    "sp.save_npz(MODELS_DIR / 'X_dev_tfidf.npz', X_dev_tfidf)\n",
    "sp.save_npz(MODELS_DIR / 'X_test_tfidf.npz', X_test_tfidf)\n",
    "\n",
    "print(\"\\nüíæ TF-IDF artifacts saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary & Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìä SPARSE METHODS COMPARISON\n",
      "================================================================================\n",
      "Method  Vocab Size  Sparsity  OOV Rate  Fit Time (s)  Transform (ms/doc)  Memory (MB)\n",
      "   OHE        2000  0.949789  0.286281      0.223587            0.124383     1.539337\n",
      "   BoW       11515  0.987852  0.070593      0.221294            0.172940     2.142155\n",
      "N-gram       18625  0.990713  0.093533      0.723580            0.374283     2.647640\n",
      "TF-IDF       11515  0.987852  0.070593      0.200188            0.140581     2.142155\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Create comparison table\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Method': ['OHE', 'BoW', 'N-gram', 'TF-IDF'],\n",
    "    'Vocab Size': [\n",
    "        ohe_metrics['V'],\n",
    "        bow_metrics['V'],\n",
    "        ngram_metrics['V'],\n",
    "        tfidf_metrics['V']\n",
    "    ],\n",
    "    'Sparsity': [\n",
    "        ohe_metrics['sparsity'],\n",
    "        bow_metrics['sparsity'],\n",
    "        ngram_metrics['sparsity'],\n",
    "        tfidf_metrics['sparsity']\n",
    "    ],\n",
    "    'OOV Rate': [\n",
    "        ohe_metrics['oov'],\n",
    "        bow_metrics['oov'],\n",
    "        ngram_metrics['oov'],\n",
    "        tfidf_metrics['oov']\n",
    "    ],\n",
    "    'Fit Time (s)': [\n",
    "        ohe_metrics['fit_s'],\n",
    "        bow_metrics['fit_s'],\n",
    "        ngram_metrics['fit_s'],\n",
    "        tfidf_metrics['fit_s']\n",
    "    ],\n",
    "    'Transform (ms/doc)': [\n",
    "        ohe_metrics['ms_per_doc'],\n",
    "        bow_metrics['ms_per_doc'],\n",
    "        ngram_metrics['ms_per_doc'],\n",
    "        tfidf_metrics['ms_per_doc']\n",
    "    ],\n",
    "    'Memory (MB)': [\n",
    "        ohe_metrics['mem_mb'],\n",
    "        bow_metrics['mem_mb'],\n",
    "        ngram_metrics['mem_mb'],\n",
    "        tfidf_metrics['mem_mb']\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä SPARSE METHODS COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ All sparse metrics saved to cache/sparse_metrics.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save all metrics to cache\n",
    "sparse_metrics = {\n",
    "    'ohe': ohe_metrics,\n",
    "    'bow': bow_metrics,\n",
    "    'ngram': ngram_metrics,\n",
    "    'tfidf': tfidf_metrics\n",
    "}\n",
    "\n",
    "with open(CACHE_DIR / 'sparse_metrics.pkl', 'wb') as f:\n",
    "    pickle.dump(sparse_metrics, f)\n",
    "\n",
    "print(\"\\nüíæ All sparse metrics saved to cache/sparse_metrics.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "‚úÖ **Completed:**\n",
    "- One-Hot Encoding (top 2000 tokens)\n",
    "- Bag-of-Words (unigram counts, min_df=2)\n",
    "- N-grams (unigrams + bigrams, min_df=3)\n",
    "- TF-IDF (with manual verification)\n",
    "- Calculated all health metrics\n",
    "- Saved all representations and metrics\n",
    "\n",
    "**Key Observations:**\n",
    "- N-grams have the largest vocabulary (includes bigrams)\n",
    "- All methods are highly sparse (>95% sparsity)\n",
    "- TF-IDF typically performs best for text classification\n",
    "- Top-500 terms capture significant portion of TF-IDF mass\n",
    "\n",
    "**Next Steps:**\n",
    "- Build dense representations (Word2Vec, GloVe)\n",
    "- Train classifiers on all representations\n",
    "- Build retrieval system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üéâ NOTEBOOK 02: SPARSE METHODS COMPLETE! üéâ\n",
      "============================================================\n",
      "\n",
      "‚úÖ Built 4 sparse representations\n",
      "‚úÖ Calculated health metrics for all methods\n",
      "‚úÖ Verified TF-IDF manual calculation\n",
      "‚úÖ Saved all artifacts to ../models\n",
      "\n",
      "üìù Ready for next notebook: 03_dense_methods.ipynb\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ NOTEBOOK 02: SPARSE METHODS COMPLETE! üéâ\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n‚úÖ Built 4 sparse representations\")\n",
    "print(f\"‚úÖ Calculated health metrics for all methods\")\n",
    "print(f\"‚úÖ Verified TF-IDF manual calculation\")\n",
    "print(f\"‚úÖ Saved all artifacts to {MODELS_DIR}\")\n",
    "print(\"\\nüìù Ready for next notebook: 03_dense_methods.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
